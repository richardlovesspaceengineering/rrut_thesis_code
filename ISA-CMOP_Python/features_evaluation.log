Host is: RUTHERFORD
Using interpreter: D:/richa/anaconda3/envs/thesis_env_windows/python.exe
New directory: /tmp/ci-yfanWgos93
File running inside: /tmp/ci-yfanWgos93/runner.py
Running problem: MW1, dimension: 2
Initialising evaluator in debug mode.

------------------------ Evaluating instance: MW1_d2 ------------------------
 
 ~~~~~~~~~~~~ RW Analysis  ~~~~~~~~~~~~ 

Initialising Random Walk Analysis 1 of 2 for MW1_d2

Generating samples (walks + neighbours) for RW features with the following properties:
- Number of walks: 2
- Number of steps per walk: 30
- Step size (% of instance domain): 1.0
- Neighbourhood size: 5

Generated RW sample 1 of 2 in 0.00 seconds.
Generated RW sample 2 of 2 in 0.00 seconds.

Evaluating populations for these RW samples...

Evaluating populations for this walk sample... (ranks off for walk steps, on for neighbours)
Evaluated population 1 of 2 in 0.05 seconds.
Evaluated population 2 of 2 in 0.06 seconds.

Initialising feature evaluation for RW features.
Evaluated RW features for sample 1 out of 2 in 0.17 seconds.
Evaluated RW features for sample 2 out of 2 in 0.20 seconds.

Evaluated all RW features

Initialising Random Walk Analysis 2 of 2 for MW1_d2

Generating samples (walks + neighbours) for RW features with the following properties:
- Number of walks: 2
- Number of steps per walk: 30
- Step size (% of instance domain): 1.0
- Neighbourhood size: 5

Generated RW sample 1 of 2 in 0.00 seconds.
Generated RW sample 2 of 2 in 0.00 seconds.

Evaluating populations for these RW samples...

Evaluating populations for this walk sample... (ranks off for walk steps, on for neighbours)
Evaluated population 1 of 2 in 0.06 seconds.
Evaluated population 2 of 2 in 0.06 seconds.

Initialising feature evaluation for RW features.
Evaluated RW features for sample 1 out of 2 in 0.13 seconds.
Evaluated RW features for sample 2 out of 2 in 0.13 seconds.

Evaluated all RW features

 
 ~~~~~~~~~~~~ Global Analysis  ~~~~~~~~~~~~ 

Generating distributed samples for Global features with the following properties:
- Num. points: 20
- Num. iterations: 20
- Method: lhs.scipy

Discrepancy: 0.002296
Generated Global sample 1 of 2 in 0.00 seconds.
Discrepancy: 0.002390
Generated Global sample 2 of 2 in 0.00 seconds.

Evaluating populations for global samples...
Evaluated Global population 1 of 2 in 0.01 seconds.
Evaluated Global population 2 of 2 in 0.01 seconds.

Initialising feature evaluation for Global features.
Evaluated Global features for sample 1 out of 2 in 0.02 seconds.
Evaluated Global features for sample 2 out of 2 in 0.02 seconds.

Evaluated all Global features

 
 ~~~~~~~~~~~~ AW Analysis  ~~~~~~~~~~~~ 

Initialising Adaptive Walk Analysis 1 of 2 for MW1_d2
Generating adaptive walk samples with the following properties:
- Number of walks: 5
- Maximum number of steps: 100
- Step size (% of instance domain): 1.0
- Neighbourhood size: 5
Generating lhs.scipy sample used as starting points for the adaptive walk...
- Sample size: 5
Discrepancy: 0.025420
Generated in 0.00 seconds.

Generated AW sample 1 of 5 in 0.03 seconds. Length: 14
Generated AW sample 2 of 5 in 0.02 seconds. Length: 8
Generated AW sample 3 of 5 in 0.03 seconds. Length: 14
Generated AW sample 4 of 5 in 0.04 seconds. Length: 18
Generated AW sample 5 of 5 in 0.02 seconds. Length: 9

Evaluating populations for these AW samples...

Evaluating populations for this walk sample... (ranks off for walk steps, on for neighbours)
Evaluated population 1 of 5 in 0.02 seconds.
Evaluated population 2 of 5 in 0.02 seconds.
Evaluated population 3 of 5 in 0.03 seconds.
Evaluated population 4 of 5 in 0.03 seconds.
Evaluated population 5 of 5 in 0.02 seconds.

Initialising feature evaluation for AW features.
Evaluated AW features for sample 1 out of 5 in 0.00 seconds.
Evaluated AW features for sample 2 out of 5 in 0.00 seconds.
Evaluated AW features for sample 3 out of 5 in 0.00 seconds.
Evaluated AW features for sample 4 out of 5 in 0.00 seconds.
Evaluated AW features for sample 5 out of 5 in 0.00 seconds.

Evaluated all AW features

Initialising Adaptive Walk Analysis 2 of 2 for MW1_d2
Generating adaptive walk samples with the following properties:
- Number of walks: 5
- Maximum number of steps: 100
- Step size (% of instance domain): 1.0
- Neighbourhood size: 5
Generating lhs.scipy sample used as starting points for the adaptive walk...
- Sample size: 5
Discrepancy: 0.020260
Generated in 0.00 seconds.

Generated AW sample 1 of 5 in 0.00 seconds. Length: 2
Generated AW sample 2 of 5 in 0.00 seconds. Length: 1
Generated AW sample 3 of 5 in 0.02 seconds. Length: 8
Generated AW sample 4 of 5 in 0.03 seconds. Length: 14
Generated AW sample 5 of 5 in 0.01 seconds. Length: 3

Evaluating populations for these AW samples...

Evaluating populations for this walk sample... (ranks off for walk steps, on for neighbours)
Evaluated population 1 of 5 in 0.00 seconds.
Evaluated population 2 of 5 in 0.00 seconds.
Evaluated population 3 of 5 in 0.01 seconds.
Evaluated population 4 of 5 in 0.02 seconds.
Evaluated population 5 of 5 in 0.01 seconds.

Initialising feature evaluation for AW features.
Evaluated AW features for sample 1 out of 5 in 0.00 seconds.
Evaluated AW features for sample 2 out of 5 in 0.00 seconds.
Evaluated AW features for sample 3 out of 5 in 0.00 seconds.
Evaluated AW features for sample 4 out of 5 in 0.00 seconds.
Evaluated AW features for sample 5 out of 5 in 0.00 seconds.

Evaluated all AW features

Successfully saved sample results to csv file for MW1_d2.

C:\Users\richa\AppData\Local\Temp\ci-yfanWgos93\features\LandscapeAnalysis.py:261: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  dat[feature_name] = [getattr(self, f"{feature_name}")]
C:\Users\richa\AppData\Local\Temp\ci-yfanWgos93\features\LandscapeAnalysis.py:261: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  dat[feature_name] = [getattr(self, f"{feature_name}")]
C:\Users\richa\AppData\Local\Temp\ci-yfanWgos93\features\LandscapeAnalysis.py:261: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  dat[feature_name] = [getattr(self, f"{feature_name}")]
C:\Users\richa\AppData\Local\Temp\ci-yfanWgos93\features\LandscapeAnalysis.py:261: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  dat[feature_name] = [getattr(self, f"{feature_name}")]
C:\Users\richa\AppData\Local\Temp\ci-yfanWgos93\features\LandscapeAnalysis.py:261: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  dat[feature_name] = [getattr(self, f"{feature_name}")]
C:\Users\richa\AppData\Local\Temp\ci-yfanWgos93\features\LandscapeAnalysis.py:261: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  dat[feature_name] = [getattr(self, f"{feature_name}")]
C:\Users\richa\AppData\Local\Temp\ci-yfanWgos93\features\LandscapeAnalysis.py:261: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  dat[feature_name] = [getattr(self, f"{feature_name}")]
C:\Users\richa\AppData\Local\Temp\ci-yfanWgos93\features\LandscapeAnalysis.py:261: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  dat[feature_name] = [getattr(self, f"{feature_name}")]
C:\Users\richa\AppData\Local\Temp\ci-yfanWgos93\features\LandscapeAnalysis.py:261: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  dat[feature_name] = [getattr(self, f"{feature_name}")]
C:\Users\richa\AppData\Local\Temp\ci-yfanWgos93\features\LandscapeAnalysis.py:261: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  dat[feature_name] = [getattr(self, f"{feature_name}")]
C:\Users\richa\AppData\Local\Temp\ci-yfanWgos93\features\LandscapeAnalysis.py:261: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  dat[feature_name] = [getattr(self, f"{feature_name}")]
C:\Users\richa\AppData\Local\Temp\ci-yfanWgos93\features\LandscapeAnalysis.py:261: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  dat[feature_name] = [getattr(self, f"{feature_name}")]
Success!
Successfully appended aggregated results to csv file.


Running problem: MW1, dimension: 5
Cleaning up /tmp/ci-yfanWgos93
